a. How to make HTTP calls from Python to consume data from a web page: To make HTTP calls and consume data from a web page in Python, you can use the `requests` library. Here's an example:
```ts
import requests

response = requests.get('https://example.com')
html_content = response.text

# Process the HTML content
```

b. What kind of information you can retrieve from the `nltk` library in Python: The `nltk` library (Natural Language Toolkit) in Python provides various functionalities for natural language processing. Some information you can retrieve from `nltk` includes:

- Tokenization: Splitting text into individual words or sentences.
 ```python
import nltk
nltk.download('punkt')

from nltk.tokenize import word_tokenize, sent_tokenize

text = "Hello, how are you? I hope you're doing well."

# Tokenize into words
words = word_tokenize(text)
print(words)
# Output: ['Hello', ',', 'how', 'are', 'you', '?', 'I', 'hope', "you're", 'doing', 'well', '.']

# Tokenize into sentences
sentences = sent_tokenize(text)
print(sentences)
# Output: ['Hello, how are you?', "I hope you're doing well."]
```
- POS Tagging: Assigning part-of-speech tags to words.
```python
import nltk
nltk.download('averaged_perceptron_tagger')

from nltk import pos_tag
from nltk.tokenize import word_tokenize

text = "I want to go to the park."

# Tokenize into words
words = word_tokenize(text)

# Perform POS tagging
pos_tags = pos_tag(words)
print(pos_tags)
# Output: [('I', 'PRP'), ('want', 'VBP'), ('to', 'TO'), ('go', 'VB'), ('to', 'TO'), ('the', 'DT'), ('park', 'NN'), ('.', '.')]

# Accessing POS tags for a specific word
print(pos_tags[0])
# Output: ('I', 'PRP')

# Accessing POS tag of a specific word
word = 'park'
pos_tag = [tag for word, tag in pos_tags if word == 'park']
print(pos_tag)
# Output: ['NN']
```
- Named Entity Recognition (NER): Identifying named entities like names, organizations, etc.
```python
import nltk
nltk.download('maxent_ne_chunker')
nltk.download('words')

from nltk import ne_chunk
from nltk.tokenize import word_tokenize

text = "Apple Inc. is planning to open a new store in New York City."

# Tokenize into words
words = word_tokenize(text)

# Perform named entity recognition (NER)
ner_tags = ne_chunk(nltk.pos_tag(words))
print(ner_tags)
# Output: (S (ORGANIZATION Apple/NNP Inc./NNP) is/VBZ planning/VBG to/TO open/VB a/DT new/JJ store/NN in/IN (GPE New/NNP York/NNP City/NNP) ./.)

# Accessing named entities
for entity in ner_tags:
    if hasattr(entity, 'label'):
        print(entity.label(), ' '.join(word for word, tag in entity.leaves()))
# Output: ORGANIZATION Apple Inc.
#         GPE New York City
```
- Stemming and Lemmatization: Reducing words to their base or root form.
```python
import nltk
nltk.download('wordnet')

from nltk.stem import PorterStemmer, WordNetLemmatizer
from nltk.tokenize import word_tokenize

text = "Running, runs, and ran are all forms of the word run."

# Tokenize into words
words = word_tokenize(text)

# Perform stemming
stemmer = PorterStemmer()
stemmed_words = [stemmer.stem(word) for word in words]
print(stemmed_words)
# Output: ['run', ',', 'run', ',', 'and', 'ran', 'are', 'all', 'form', 'of', 'the', 'word', 'run', '.']

# Perform lemmatization
lemmatizer = WordNetLemmatizer()
lemmatized_words = [lemmatizer.lemmatize(word) for word in words]
print(lemmatized_words)
# Output: ['Running', ',', 'run', ',', 'and', 'ran', 'are', 'all', 'form', 'of', 'the', 'word', 'run', '.']
```
- Sentiment Analysis: Determining the sentiment (positive, negative, neutral) of a text.
```python
import nltk
nltk.download('vader_lexicon')

from nltk.sentiment import SentimentIntensityAnalyzer

text = "I love this movie! It's amazing."

# Perform sentiment analysis
analyzer = SentimentIntensityAnalyzer()
sentiment_scores = analyzer.polarity_scores(text)
print(sentiment_scores)
# Output: {'neg': 0.0, 'neu': 0.141, 'pos': 0.859, 'compound': 0.7322}

# Accessing the compound sentiment score
compound_score = sentiment_scores['compound']
print(compound_score)
# Output: 0.7322

# Determining the overall sentiment
if compound_score >= 0.05:
    sentiment = 'Positive'
elif compound_score <= -0.05:
    sentiment = 'Negative'
else:
    sentiment = 'Neutral'
print(sentiment)
# Output: Positive
```

c. How to write/read data to/from a file in Python: To write and read data to/from a file in Python, you can use file handling operations. Here are examples of writing and reading data:
```ts
# Write data to a file
with open('file.txt', 'w') as file:
    file.write('Hello, World!')

# Read data from a file
with open('file.txt', 'r') as file:
    data = file.read()
    print(data)
```